\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{nameref}
\usepackage{cite}

\usetikzlibrary{automata,positioning}


\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\chead{\hmwkTitle}
\lhead{\hmwkAuthorName}
\rhead{\hmwkClass}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}
\newcommand{\sur}[1]{\ensuremath{^{\textrm{#1}}}}
\newcommand{\sous}[1]{\ensuremath{_{\textrm{#1}}}}

\setlength\parindent{0pt}

%c
% Create Problem Sections
%

\newtheorem{lemma}{Lemma}[section]
\newtheorem{exercise}{Exercise}
%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework 3}
\newcommand{\hmwkDueDate}{October 17th, 2018}
\newcommand{\hmwkClass}{Math 225A Differential Topology}
\newcommand{\hmwkClassInstructor}{Professor Peter Petersen}
\newcommand{\hmwkAuthorName}{\textbf{Anish Chedalavada}}

%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \vspace{0.1in}
    \textmd{\hmwkDueDate} \\
    \vspace{0.2in}\large{\textit{\hmwkClassInstructor\  }}
    \vspace{2in}
}

\author{\hmwkAuthorName}
\date{}


\begin{document}

\maketitle

\pagebreak

\begin{exercise}
Show that if $f: X \to Y$ is a submersion then $f$ maps open sets to open sets.
  \end{exercise}

  \begin{proof}
    By the local submersion theorem, we have that $f$ is locally equivalent to the canonical submersion for $x \in X$,$y\in Y$ s.t. $f(x) = y$ is a submersion. Let $U \subset X$ be an open set containing $x \in X$. Without loss of generality, we may select a neighborhood $x \in N(x)$ with local coordinates for $N(x), f(N(x))$ fulfilling the local submersion theorem, and shrink $N(x)$ s.t. $N(x) \subset U$. The product topology on $R^{n}$ for $N(x)$ diffeomorphic to $V \subset R^{n}$ yields that the projection of any open set onto any subspace yields an open set, i.e. that the projection map is an open map. As $f$ is equivalent to the canonical submersion for $N(x)$, we have that the image of $f$ on $N(x)$ must be an open set in $Y$. Thus, for any arbitrary $x \in f(U)$ we have a neighborhood $f(x) \in f(N(x)) \subset f(U)$ as constructed above, yielding the claim.
  \end{proof}

  \begin{exercise}
    Show that every submersion of a compact space into a connected space is surjective. In particular, show that there exist no submersions of compact manifolds into Euclidean spaces.
  \end{exercise}

  \begin{proof}
    From the previous exercise, we have that the image of an open set under a submersion is an open set. Thus, for $f:X \to Y$ with $X$ compact, $Y$ connected, we have that the image $f(X)$ must be open as $X \subset X$ open. However, $X$ is compact, $f$ is continuous, and thus $f(X)$ must be closed. As $Y$ is connected, this implies the only clopen set is $Y$ itself, and thus $f(X) = Y$. In particular, we have that as Euclidean space is connected and not compact, there are no continuous surjections from a compact space to all of Euclidean space and therefore no submersions.
  \end{proof}

  \begin{exercise}
    For any homogenous polynomial $p$ in $k$-variables, show that the preimage of any point $a \neq 0$ is a $k-1$ dimensional submanifold of $\mathbb{R}^{k}$.
  \end{exercise}
  \begin{proof}
    Let $p$ be a homogenous polynomial in $k$ variables, i.e. $p(tx_{1},...,tx_{k}) = t^{m}p(x_{1},...,x_{k})$. We have from this that
    \begin{align*}
      \frac{\partial}{\partial t} t^{m}p(x_{1},...,x_{k}) & = \frac{\partial}{\partial t} p(tx_{1},...,tx_{k}) \\
      mt^{m-1}p(x_{1},...,x_{k}) & = \frac{\partial p}{\partial (tx_{1})} \frac{\partial tx_{1}}{\partial t} + ... +  \frac{\partial p}{\partial (tx_{k})} \frac{\partial tx_{k}}{\partial t} \\
    \end{align*}

    Letting $t = 1$ yields
    \[
      \sum_{i=1}^{k} \frac{\partial p}{\partial x_{i}} x_{i} = m \cdot p
    \]

    Which is precisely the result that $\nabla p_{x} \cdot \vec{x} = m \cdot p(x)$, or that the only values of $x$ for which $x$ lies in the kernel of $D_{p}$ are the values for which $p(x) = 0$. Thus, for $0 \neq a \in \mathbb{R}$ we have that $Dp$ must be surjective on the tangent space of $a$ (as $x$ is mapped onto the 1-dimensional tangent space) and thus $p$ is a submersion, implying that $p^{-1}(a)$ is a $k-1$ dimension submanifold by the regular value theorem. Furthermore, we have that for $a > 0$ or $a < 0$ and $p(\vec{x}) = a$, the isomorphism $\vec{x} \mapsto t\vec{x}$ induces a map $p(x) \mapsto t^{m}p(x)$ by homogeneity. Let $a, b > 0$. Then the map

    \[
      \vec{x} \mapsto \left(\frac{a}{b}\right)^{\frac{1}{m}} \vec{x} \text{ induces a map } p(x) \mapsto \frac{a}{b} p(x)
    \]

    which clearly sends the preimage of $b$ to the preimage of $a$ via a linear isomorphism, which is a diffeomorphism. Symmetric logic applies for $a,b < 0$ using absolute values. Thus, the preimage manifolds of any two points on $R^{k}$ that both have the same sign are diffeomorphic.  
  \end{proof}

  \pagebreak

  \begin{exercise}
Prove the stack of records theorem.
    \end{exercise}

    \begin{proof}
      We have that $X$ is compact and has the same dimension as $Y$: as $y$ is a regular value, the inverse function theorem yields that at every given point $x$ mapped to $y$ (they are points as the preimage of $y$ is a 0-dimensional submanifold by preimage theorem), there is a neighborhood of $x$ that is mapped diffeomorphically onto a neighborhood of $y$. This immediately yields that the preimage of $y$ must be a finite set of points, as the collection of neighborhoods that are mapped diffeomorphically onto the neighborhood of $y$ form a cover of the preimage of $y$. The preimage of $y$ must be compact, and thus there is a finite subcover of this collection that covers the preimage of $y$. By pigeonhole principle, if there are infinite points, one neighborhood must contain two points in the preimage of $y$, a contradiction, as $f$ is injective on these neighborhoods. Thus, the preimage of $y$ is a finite set of points $\{x_{i}}$. Let $U_{i}$ be the collection of neighborhoods of associated $x_{i}$ on which $f$ is a diffeomorphism, and $V_{i} = f(U_{i})$. We have that $f(K) = f(X - \bigcup_{i}U_{i})$ is closed, and $V = \bigcap_{i}V_{i} - f(K)$ is a neighborhood of $y$. Let $\widetilde U_{i} = f^{-1}(V)$, we have that $\widetilde U_{i} \subset U$. We also may shrink the $U_{i}$ sufficiently such that they are disjoint. The  $\widetilde U_{i}$ thus form the explicit preimage of $V$ by construction, and each is mapped diffeomorphically onto its image. 
    \end{proof}

    
  \begin{exercise}
Prove that any polynomial in one variable is a submersion from $\mathbb{C} \to \mathbb{C}$ except at finitely many points.
\end{exercise}

\begin{proof}
  Suffices to show that the derivative of any polynomial has only finitely many roots, as this proves that except for finitely many points, the linear transformation $p'(x): \mathbb{C} \to \mathbb{C}$ is nonzero and thus is a surjection, the domain being a one-dimensional complex vector space. We will show that any finite-degree polynomial can have at most finitely many roots, which will give us the claim. Suppose we have $\alpha$ a root of some polynomial $p = a_{n}z^{n}+...+a_{0}$, we have that the root $(t - \alpha) \ | \ p(x)$ or $p(x) = q(x) (t - \alpha)$ from ring theory. We must have that $q(x)$ cannot have degree greater than $n$, as $t$ is an indeterminate and $t * t^{m} = t^{m+1}$, implying that the degree of $p(x) = t^{m+1}$ for $m$ the degree of $q$. Applying an inductive argument on degree yields the claim.  
\end{proof}

\begin{exercise}
Show that the orthogonal group $O(n)$ is compact.
\end{exercise}

\begin{proof}
The orthogonal group $O(n)$ is the preimage of a singleton set and is thus closed. We have that if $A \in O(n)$ then $A^{t} = A^{-1}$. In particular, this means that for a given row vector $(a_{i1},...,a_{in}$, the product $AA^{t} = I \implies (a_{i1},...,a_{in}) \cdot (a_{i1},...,a_{in}) = 1$, or $\sum_{j}a_{ij}^{2} = 1$. Thus, we have that for any fixed $1< i < n$, the points $a_{i1},...,a_{in}$ must lie on an $n$-sphere as the row vector has norm $1$. We thus have that the row vectors in $O(n)$ are selected from $n$ linearly independent row vectors in $S(n)$. Thus, the first row is selected from $S^{n}$. As the second row must be linearly independent from the first row, we have that the second row is selected from the projection of $S^{n}$ onto the $k-1$ dimensional space orthogonal to the first row vector, which is equal to $S^{n-1}$ (the projection of the $n$-disk onto $n-1$ space is the $n-1$-disk). Thus, the second row vector is selected from $S^{n-1}$, and we may proceed inductively to show that the $i^{th}$ row vector is selected from $S^{n-i + 1}$. Thus, $O(n)$ is a subset of the product $\prod_{i=1}^{n} S^{i}$, which is a product of compact spaces and is thus compact. (The $n$-sphere is closed and bounded and thus compact by the Heine-Borel theorem, and $O(n)$ is a closed subset of a compact space).   
\end{proof}

\begin{exercise}
  Verify that the tangent space to $O(n)$ at the identity is the vector space of skew-symmetric matrices. 
\end{exercise}

\begin{proof}
We have that the tangent space to $O(n)$ is the kernel of the map $Df_{I}$ induced by $f: A \mapsto A^{t}A$, by the local submersion theorem. We have that $Df_{A}(B) = BA^{t} + AB^{t}$. At the identity, we thus have that $Df_{I}(B) = B^{t} + B$, which is 0 if and only if $B$ is skew-symmetric. The result follows. 
\end{proof}

\pagebreak

\begin{exercise}
Prove that the set of 2 $\times$ 2 matrices of rank 1 is a three dimensional submanifold of $\mathbb{R}^{k}$. 
\end{exercise}

\begin{proof}
  We can explicitly compute the derivative of the determinant for 2$\times$ 2 matrices in terms of the Euclidean coordinates spanning the matrices. Let:

  \[
    A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}, \ B = \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix} 
  \]

  Evaluating the derivative as in a Euclidean space, we have:
  
  \begin{align*}
 D \text{det}_{A}(B) = \lim_{s \to 0}\frac{\det(A+sB) - \det(A)}{s} & = \lim_{s\to 0} \frac{ad + sa'd + asd' + s^{2}a'd' - bc - bsc' - sb'c - s^{2}b'c' -ad + bc}{s} \\ & = \lim_{s\to 0} \ a'd + ad' - b'c - bc' + sa'd' - sb'c'
\end{align*}

This can be evaluated and rewritten as:

\[
D \text{det}_{A}(B) = \det \begin{pmatrix} a' & b \\ c' & d \end{pmatrix} + \det \begin{pmatrix} a & b' \\ c & d' \end{pmatrix}
\]

It is easy to see that it is possible to select $B$ s.t. the above operator is nonzero for $A \neq 0$, as all one need do is select a linearly independent vector from the nonzero column vector of $A$, (as it is rank 1), yielding a 2x2 matrix with two linearly independent columns and thus nonzero determinant: i.e. on $\mathbb{M}_{2}(\mathbb{R}) - 0$ the determinant has $0$ as a regular value: thus the preimage of 0 is a three dimensional submanifold by the regular value theorem, and the only nonzero 2$\times$2 matrices with 0 determinant are matrices with rank 1. The result follows. 
\end{proof}

\begin{exercise}
  Prove that the set of $m \times n$ matrices of rank r is a submanifold of $\mathbb{R}^{mn}$ of codimension $(m-r)(n-r)$. 
  \end{exercise}
  \begin{proof}
    For simplicity, we may represent every $r$ rank $m\times n$ matrix as

    \[
      \begin{pmatrix} B & C \\ D & E \end{pmatrix}
    \]

    Where $B$ is $r\times r$ rank $r$, $C$ is $r \times (n -r)$, $D$ is $(m-r) \times r$ and $E$ is $(m-r)(n-r)$. Postmultiplying the above matrix as below, we have:

    \[
      \begin{pmatrix} B & C \\ D & E \end{pmatrix} \begin{pmatrix} I & -B^{-1}C \\ 0 & I \end{pmatrix} =  \begin{pmatrix} B & C - C \\ D & E - DB^{-1}C \end{pmatrix}
    \]

    Using Gaussian elimation, we have that the above matrix must be equivalent to

    \[
 \begin{pmatrix} I & 0 \\ 0 & E - DB^{-1}C \end{pmatrix}
\]

Which is of rank $r$ if and only if $E - DB^{-1}C = 0$. We have a smooth linear map from $R^{mn} \to R^{(m-r)(n-r)}$ given by $A \mapsto E - DB^{-1}C$ with $A$ decomposed into $B, D, C, E$ as above. This map is clearly smooth as it is a linear map consisting first of the postmultiplication above (the function at any given point is a linear isomorphism, thus differentiable at a point with the differential being an isomorphism: and thus it is locally smooth by the inverse function theorem) and then the vector space projection onto the bottom right $(m-r)(n-r)$ Jordan block. As the postmultiplication above is merely a change of basis, we may only consider the vector space projection onto the Jordan block described above, which is necessarily surjective as the postmultiplication is clearly invertible and thus an isomorphism at any given point, while the projection onto the lower right Jordan block from the entire space must be surjective. Thus, this operator is a submersion, and the preimage of $0$ is the set of all $r \times r$ matrices, which is of codimension $(m-r)(n-r)$ by the preimage theorem. 
    \end{proof}
\end{document}